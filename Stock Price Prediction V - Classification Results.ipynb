{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our two classifiers are ready to predict which stock price will see a 5% increase tomorrow, let's test them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something interesting to investigate is if the models can only predict price increase for stocks it has been trained with, or if they can generalize to all stocks as-is, without having to be re-trained on a dataset that would include each new stock's historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.23.1)\n",
      "Requirement already satisfied: scikit-plot in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.7)\n",
      "Requirement already satisfied: ta in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.5.25)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (2.23.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (1.25.8)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 1)) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RF model\n",
    "rf_model = pickle.load(open('randomforest-clf.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KNN model\n",
    "kn_model = pickle.load(open('kneighbors-clf.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a new test dataset, exclusively made of stocks absent from the initial training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing HO.PA! new X_df shape: (5273, 86), new y_df shape: (5273, 1)\n",
      "Done processing ALCAR.PA! new X_df shape: (7329, 86), new y_df shape: (7329, 1)\n",
      "Check number of NaNs in X_df: 0, and in y_df: 0\n",
      "New testing set contains 1.62% records labeled as 1\n"
     ]
    }
   ],
   "source": [
    "symbol_list = ['HO.PA', 'ALCAR.PA']\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "\n",
    "for symbol in symbol_list:\n",
    "    symbol_X_df = utils.get_stock_feature_dataset(symbol)\n",
    "    symbol_X_df, symbol_y_df = utils.make_labels_dataset(symbol_X_df)\n",
    "\n",
    "    # reset index since dates are not required for classification\n",
    "    X_df = X_df.append(symbol_X_df.reset_index(drop=True), ignore_index=True)\n",
    "    y_df = y_df.append(symbol_y_df.reset_index(drop=True), ignore_index=True)\n",
    "    print('Done processing {}! new X_df shape: {}, new y_df shape: {}'.format(symbol, X_df.shape, y_df.shape))\n",
    "\n",
    "X_df = X_df.astype(float)\n",
    "X_df.replace(np.inf, np.nan, inplace=True)\n",
    "X_df.replace(-np.inf, np.nan, inplace=True)\n",
    "X_df.interpolate(axis=0, limit_direction='both', inplace=True)\n",
    "\n",
    "print('Check number of NaNs in X_df: {}, and in y_df: {}'.format(X_df.isna().sum().sum(), y_df.isna().sum().sum()))\n",
    "\n",
    "print('New testing set contains {:.2f}% records labeled as 1'.format(y_df.values.sum()/y_df.shape[0] * 100))\n",
    "\n",
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(X_df.values)\n",
    "X_scaled = X_scaler.transform(X_df.values)\n",
    "y_true = y_df.values.reshape(-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kn_model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN model:\n",
      "\taccuracy: 98.01%\n",
      "\tprecision: 11.43%\n",
      "\tfbeta: 0.077\n"
     ]
    }
   ],
   "source": [
    "print('Results for KNN model:')\n",
    "print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, y_pred) * 100))\n",
    "print('\\tprecision: {:.2f}%'.format(precision_score(y_true, y_pred) * 100))\n",
    "print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, y_pred, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RF model:\n",
      "\taccuracy: 98.38%\n",
      "\tprecision: 0.00%\n",
      "\tfbeta: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Results for RF model:')\n",
    "print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, y_pred) * 100))\n",
    "print('\\tprecision: {:.2f}%'.format(precision_score(y_true, y_pred) * 100))\n",
    "print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, y_pred, beta=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that both models are not good at predicting increase for stocks outside of their training set.\n",
    "\n",
    "Let's now check results obtained on stocks that KNN and RF models have been trained on, and see if their predictions were true. For this, I will make them predict for all of the stocks included in the training set, and check if there was an increase or not on the day after.\n",
    "\n",
    "I start by building the prediction set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stock_list = ['AI.PA', 'SAF.PA', 'GNFT.PA', 'ALNOV.PA', 'FDJ.PA', 'ETL.PA', 'DBV.PA',\n",
    "                       'BN.PA', 'KER.PA', 'AIR.PA', 'ENGI.PA', 'FP.PA', 'DG.PA', 'VIV.PA',\n",
    "                       'UG.PA', 'SU.PA', 'VIE.PA', 'ALPHA.PA', 'ALBIO.PA', 'CRI.PA', 'ALERS.PA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-466c9fc08885>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msymbol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_stock_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Download data for today, July 8th 2020\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mX_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stock_feature_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1594195200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1594231200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpred_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\autotrade\\utils.py\u001b[0m in \u001b[0;36mget_stock_feature_dataset\u001b[1;34m(symbol, start, end)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Add technical analysis indicators as features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_all_ta_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Open'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'High'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Low'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Close'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Volume'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# Add historical data for major indices as features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\wrapper.py\u001b[0m in \u001b[0;36madd_all_ta_features\u001b[1;34m(df, open, high, low, close, volume, fillna, colprefix)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \"\"\"\n\u001b[0;32m    326\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_volume_ta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolume\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_volatility_ta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_trend_ta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_momentum_ta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvolume\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\wrapper.py\u001b[0m in \u001b[0;36madd_volatility_ta\u001b[1;34m(df, high, low, close, fillna, colprefix)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# Average True Range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     df[f'{colprefix}volatility_atr'] = AverageTrueRange(\n\u001b[1;32m--> 104\u001b[1;33m         close=df[close], high=df[high], low=df[low], n=10, fillna=fillna).average_true_range()\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;31m# Bollinger Bands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\volatility.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, high, low, close, n, fillna)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fillna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfillna\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\volatility.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_true_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_high\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_low\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0matr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0matr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0matr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0matr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0matr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "pred_X = pd.DataFrame()\n",
    "\n",
    "for symbol in training_stock_list:\n",
    "    # Download data for today, July 8th 2020\n",
    "    X_df = utils.get_stock_feature_dataset(symbol, 1594195200, 1594231200)\n",
    "    pred_X = pred_X.append(X_df.reset_index(drop=True), ignore_index=True)\n",
    "\n",
    "pred_X = pred_X.astype(float)\n",
    "pred_X.replace(np.inf, np.nan, inplace=True)\n",
    "pred_X.replace(-np.inf, np.nan, inplace=True)\n",
    "pred_X.interpolate(axis=0, limit_direction='both', inplace=True)\n",
    "\n",
    "print('Check number of NaNs in pred_X: {}'.format(X_df.isna().sum().sum()))\n",
    "\n",
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(pred_X.values)\n",
    "pred_X_scaled = X_scaler.transform(pred_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131.100006</td>\n",
       "      <td>133.449997</td>\n",
       "      <td>130.449997</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>564014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.099998</td>\n",
       "      <td>90.919998</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>90.160004</td>\n",
       "      <td>90.160004</td>\n",
       "      <td>505772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.912000</td>\n",
       "      <td>5.030000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>4.974000</td>\n",
       "      <td>4.974000</td>\n",
       "      <td>372150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.210000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>3.060000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>834793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.190001</td>\n",
       "      <td>28.219999</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>27.990000</td>\n",
       "      <td>113035.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close   Adj Close    Volume\n",
       "0  131.100006  133.449997  130.449997  132.750000  132.750000  564014.0\n",
       "1   90.099998   90.919998   88.599998   90.160004   90.160004  505772.0\n",
       "2    4.912000    5.030000    4.830000    4.974000    4.974000  372150.0\n",
       "3    3.210000    3.210000    3.060000    3.110000    3.110000  834793.0\n",
       "4   28.190001   28.219999   27.760000   27.990000   27.990000  113035.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions\n",
    "kn_pred_y = kn_model.predict(pred_X_scaled)\n",
    "rf_pred_y = rf_model.predict(pred_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save KNN preds to a file\n",
    "outfile = open('kneighbors-preds.pickle', 'wb')\n",
    "np.save(outfile, kn_pred_y)\n",
    "outfile.close()\n",
    "\n",
    "# Same for RF predictions\n",
    "outfile = open('randomforest-preds.pickle', 'wb')\n",
    "np.save(outfile, rf_pred_y)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today is now July 9th 2020, market is now closed, let's check yesterday's predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the true target dataset:\n",
    "\n",
    "y_true = pd.DataFrame()\n",
    "\n",
    "for symbol in training_stock_list:\n",
    "    # Download data for July 8th pre-open and 9th post-close\n",
    "    X_df = utils.get_stock_feature_dataset(symbol, 1594195200, 1594317600)\n",
    "    X_df, y_df = utils.make_labels_dataset(X_df)\n",
    "    y_true = y_true.append(y_df.reset_index(drop=True), ignore_index=True)\n",
    "\n",
    "y_true = y_df.values.reshape(-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions made yesterday\n",
    "kn_pred_y = np.load(open('kneighbors-preds.pickle', 'rb'))\n",
    "rf_pred_y = np.load(open('randomforest-preds.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results for KNN model:')\n",
    "print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, kn_pred_y) * 100))\n",
    "print('\\tprecision: {:.2f}%'.format(precision_score(y_true, kn_pred_y) * 100))\n",
    "print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, kn_pred_y, beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results for RF model:')\n",
    "print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, rf_pred_y) * 100))\n",
    "print('\\tprecision: {:.2f}%'.format(precision_score(y_true, rf_pred_y) * 100))\n",
    "print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, rf_pred_y, beta=0.5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
