{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have previously appplied several regression models and analyzed their results. They were not reliable enough to be used for real-world portfolio management.\n",
    "\n",
    "Another way to approach the main problem of stock market investing is to consider it as a classification problem: can a model predict well enough if a stock price will increase by 5% or more in the next day ?\n",
    "\n",
    "Let's investigate by building the appropriate dataset, and train various classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.23.1)\n",
      "Requirement already satisfied: ta in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.5.25)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (2.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 1)) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, fbeta_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "X_df = utils.get_stock_feature_dataset('ALNOV.PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>cac40_Open</th>\n",
       "      <th>cac40_High</th>\n",
       "      <th>cac40_Low</th>\n",
       "      <th>cac40_Close</th>\n",
       "      <th>sbf120_Open</th>\n",
       "      <th>sbf120_High</th>\n",
       "      <th>sbf120_Low</th>\n",
       "      <th>sbf120_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-12</th>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.561258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3401.260010</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3389.080078</td>\n",
       "      <td>3389.080078</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15</th>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.561258</td>\n",
       "      <td>-2.528736</td>\n",
       "      <td>3387.760010</td>\n",
       "      <td>3439.520020</td>\n",
       "      <td>3387.760010</td>\n",
       "      <td>3420.280029</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-16</th>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>2.561258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3443.600098</td>\n",
       "      <td>3500.939941</td>\n",
       "      <td>3428.969971</td>\n",
       "      <td>3500.939941</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-17</th>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229621</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>3503.820068</td>\n",
       "      <td>3530.790039</td>\n",
       "      <td>3494.350098</td>\n",
       "      <td>3527.500000</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-18</th>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.253578</td>\n",
       "      <td>1.494253</td>\n",
       "      <td>3527.760010</td>\n",
       "      <td>3542.580078</td>\n",
       "      <td>3508.399902</td>\n",
       "      <td>3535.179932</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close  Volume  volume_adi  \\\n",
       "Date                                                                 \n",
       "2012-10-12  8.70  8.70  8.70   8.70       8.70   450.0         0.0   \n",
       "2012-10-15  8.48  8.48  8.48   8.48       8.48   730.0         0.0   \n",
       "2012-10-16  8.70  8.70  8.70   8.70       8.70  3000.0         0.0   \n",
       "2012-10-17  8.72  8.72  8.72   8.72       8.72   800.0         0.0   \n",
       "2012-10-18  8.83  8.83  8.83   8.83       8.83   138.0         0.0   \n",
       "\n",
       "            volume_obv  volume_cmf  volume_fi  ...  others_dlr  others_cr  \\\n",
       "Date                                           ...                          \n",
       "2012-10-12       450.0         0.0 -24.874197  ...   -2.561258   0.000000   \n",
       "2012-10-15      -280.0         0.0 -24.874197  ...   -2.561258  -2.528736   \n",
       "2012-10-16      2720.0         0.0 -24.874197  ...    2.561258   0.000000   \n",
       "2012-10-17      3520.0         0.0 -24.874197  ...    0.229621   0.229885   \n",
       "2012-10-18      3658.0         0.0 -24.874197  ...    1.253578   1.494253   \n",
       "\n",
       "             cac40_Open   cac40_High    cac40_Low  cac40_Close  sbf120_Open  \\\n",
       "Date                                                                          \n",
       "2012-10-12  3401.260010  3419.000000  3389.080078  3389.080078  2607.149902   \n",
       "2012-10-15  3387.760010  3439.520020  3387.760010  3420.280029  2630.100098   \n",
       "2012-10-16  3443.600098  3500.939941  3428.969971  3500.939941  2686.030029   \n",
       "2012-10-17  3503.820068  3530.790039  3494.350098  3527.500000  2704.060059   \n",
       "2012-10-18  3527.760010  3542.580078  3508.399902  3535.179932  2709.370117   \n",
       "\n",
       "            sbf120_High   sbf120_Low  sbf120_Close  \n",
       "Date                                                \n",
       "2012-10-12  2607.149902  2607.149902   2607.149902  \n",
       "2012-10-15  2630.100098  2630.100098   2630.100098  \n",
       "2012-10-16  2686.030029  2686.030029   2686.030029  \n",
       "2012-10-17  2704.060059  2704.060059   2704.060059  \n",
       "2012-10-18  2709.370117  2709.370117   2709.370117  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_dataset(X_df, increase=0.05, label_name='increase_tomorrow'):\n",
    "    '''\n",
    "        increase: float between 0 and 1, equivalent to the desired % increase when multiplied by 100\n",
    "        label_name: name for the column containing labels\n",
    "    '''\n",
    "\n",
    "    # Build the target dataset: label 1 if stock price increased by 5% or more in the following days, 0 otherwise\n",
    "    y_df = pd.DataFrame(index=X_df.index, columns=[label_name])\n",
    "    for i in range(len(X_df) - 1):\n",
    "        increase_threshold = X_df['Adj Close'].iloc[i] + increase * X_df['Adj Close'].iloc[i]\n",
    "        y_df.iloc[i] = 1 if X_df['Adj Close'].iloc[i+1] > increase_threshold else 0\n",
    "\n",
    "    # Drop last row, for which there is no label\n",
    "    X_df.drop(X_df.tail(1).index, inplace=True)\n",
    "    y_df.drop(y_df.tail(1).index, inplace=True)\n",
    "\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = make_labels_dataset(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>increase_tomorrow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           increase_tomorrow\n",
       "Date                        \n",
       "2020-06-29                 0\n",
       "2020-06-30                 0\n",
       "2020-07-01                 0\n",
       "2020-07-02                 1\n",
       "2020-07-03                 0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's check if this 31.62% increase is correctly labeled...\n",
      "Good!\n"
     ]
    }
   ],
   "source": [
    "# Check that labels are correct:\n",
    "\n",
    "# There was an important increase of our stock price on the market day just after April 9th 2020\n",
    "print(\"Let's check if this {:.2f}% increase is correctly labeled...\".format((X_df.loc['2020-04-14']['Adj Close'] - X_df.loc['2020-04-09']['Adj Close']) / X_df.loc['2020-04-09']['Adj Close'] * 100))\n",
    "\n",
    "# Get index of April 9th 2020, the day before increase\n",
    "idx = len(X_df.loc[:'2020-04-09']) - 1\n",
    "assert np.array_equal(X_df.loc['2020-04-09'].values, X_df.iloc[idx].values)\n",
    "\n",
    "# Check that its corresponding label is 1\n",
    "assert y_df.iloc[idx]['increase_tomorrow'] == 1\n",
    "\n",
    "print('Good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split dataset into testing and training datasets, and normalize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 90-10% training-testing sets.\n",
    "# They can be shuffled safely, since the specificities of\n",
    "# time series are not relevant anymore for our classification task\n",
    "train_X, train_y, test_X, test_y = utils.split_dataset(X_df, y_df, train_size=0.9, do_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains 7.33% records labeled as 1\n",
      "testing set contains 8.63% records labeled as 1\n"
     ]
    }
   ],
   "source": [
    "# Check if there are both labels in the training and testing sets\n",
    "print('training set contains {:.2f}% records labeled as 1'.format((train_y.values.sum()/train_y.shape[0] * 100)))\n",
    "print('testing set contains {:.2f}% records labeled as 1'.format(test_y.values.sum()/test_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(train_X.values)\n",
    "\n",
    "train_X_scaled = X_scaler.transform(train_X.values)\n",
    "test_X_scaled = X_scaler.transform(test_X.values)\n",
    "\n",
    "train_y = train_y.values.reshape(-1)\n",
    "test_y = test_y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first use the benchmark algorithm 'DummyClassifier', and then apply and test LinearSVC, LogisticRegression, SVC, KNeighborsClassifier, RandomForestClassifier and AdaBoostClassifier.\n",
    "\n",
    "The metrics I will evaluate for this classification task are accuracy, precision and Fbeta-score with beta=0.5 to penalize false positives more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, y_pred) * 100))\n",
    "    print('\\tprecision: {:.2f}%'.format(precision_score(y_true, y_pred) * 100))\n",
    "    print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, y_pred, beta=0.5)))\n",
    "\n",
    "def train_eval(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    print('Results:')\n",
    "    print_metrics(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 82.74%\n",
      "\tprecision: 0.00%\n",
      "\tfbeta: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_eval(DummyClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 74.62%\n",
      "\tprecision: 17.65%\n",
      "\tfbeta: 0.204\n"
     ]
    }
   ],
   "source": [
    "train_eval(LinearSVC(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 78.68%\n",
      "\tprecision: 17.95%\n",
      "\tfbeta: 0.202\n"
     ]
    }
   ],
   "source": [
    "train_eval(SGDClassifier(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 75.63%\n",
      "\tprecision: 19.61%\n",
      "\tfbeta: 0.226\n"
     ]
    }
   ],
   "source": [
    "train_eval(LogisticRegression(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 75.63%\n",
      "\tprecision: 19.61%\n",
      "\tfbeta: 0.226\n"
     ]
    }
   ],
   "source": [
    "train_eval(SVC(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 91.37%\n",
      "\tprecision: 50.00%\n",
      "\tfbeta: 0.303\n"
     ]
    }
   ],
   "source": [
    "train_eval(KNeighborsClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 91.88%\n",
      "\tprecision: 66.67%\n",
      "\tfbeta: 0.345\n"
     ]
    }
   ],
   "source": [
    "train_eval(RandomForestClassifier(n_estimators=2000, class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 90.86%\n",
      "\tprecision: 40.00%\n",
      "\tfbeta: 0.270\n"
     ]
    }
   ],
   "source": [
    "weak_learner = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "ada_model = AdaBoostClassifier(weak_learner, algorithm=\"SAMME\", n_estimators=2000)\n",
    "train_eval(ada_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision scores obtained by RandomForestClassifier and AdaBoostClassifier are almost good, but their Fscore results aren't, and it seems from their accuracy results that both models are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then try to get less overfitting and better precision and fbeta scores by aggregating a lot more stocks than just one in our training and testing sets, and re-train all these models on much more data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! new X_df shape: (5272, 86), new y_df shape: (5272, 1)\n",
      "\n",
      "Processing SAF.PA...\n",
      "Done! new X_df shape: (10544, 86), new y_df shape: (10544, 1)\n",
      "\n",
      "Processing GNFT.PA...\n",
      "Done! new X_df shape: (14003, 86), new y_df shape: (14003, 1)\n",
      "\n",
      "Processing ALNOV.PA...\n",
      "Done! new X_df shape: (15974, 86), new y_df shape: (15974, 1)\n",
      "\n",
      "Processing FDJ.PA...\n",
      "Done! new X_df shape: (16131, 86), new y_df shape: (16131, 1)\n",
      "\n",
      "Processing ETL.PA...\n",
      "Done! new X_df shape: (19859, 86), new y_df shape: (19859, 1)\n",
      "\n",
      "Processing DBV.PA...\n",
      "Done! new X_df shape: (21968, 86), new y_df shape: (21968, 1)\n",
      "\n",
      "Processing BN.PA...\n",
      "Done! new X_df shape: (29739, 86), new y_df shape: (29739, 1)\n",
      "\n",
      "Processing KER.PA...\n",
      "Done! new X_df shape: (35011, 86), new y_df shape: (35011, 1)\n",
      "\n",
      "Processing AIR.PA...\n",
      "Done! new X_df shape: (39848, 86), new y_df shape: (39848, 1)\n",
      "\n",
      "Processing ENGI.PA...\n",
      "Done! new X_df shape: (45120, 86), new y_df shape: (45120, 1)\n",
      "\n",
      "Processing FP.PA...\n",
      "Done! new X_df shape: (50392, 86), new y_df shape: (50392, 1)\n",
      "\n",
      "Processing DG.PA...\n",
      "Done! new X_df shape: (55664, 86), new y_df shape: (55664, 1)\n",
      "\n",
      "Processing VIV.PA...\n",
      "Done! new X_df shape: (60936, 86), new y_df shape: (60936, 1)\n",
      "\n",
      "Processing UG.PA...\n",
      "Done! new X_df shape: (66208, 86), new y_df shape: (66208, 1)\n",
      "\n",
      "Processing SU.PA...\n",
      "Done! new X_df shape: (71480, 86), new y_df shape: (71480, 1)\n",
      "\n",
      "Processing VIE.PA...\n",
      "Done! new X_df shape: (76609, 86), new y_df shape: (76609, 1)\n",
      "\n",
      "Processing ALPHA.PA...\n",
      "Done! new X_df shape: (77623, 86), new y_df shape: (77623, 1)\n",
      "\n",
      "Processing ALBIO.PA...\n",
      "Done! new X_df shape: (79992, 86), new y_df shape: (79992, 1)\n",
      "\n",
      "Processing CRI.PA...\n",
      "Done! new X_df shape: (86184, 86), new y_df shape: (86184, 1)\n",
      "\n",
      "Processing ALERS.PA...\n",
      "Done! new X_df shape: (88239, 86), new y_df shape: (88239, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "symbol_list = ['AI.PA', 'SAF.PA', 'GNFT.PA', 'ALNOV.PA', 'FDJ.PA', 'ETL.PA', 'DBV.PA',\n",
    "              'BN.PA', 'KER.PA', 'AIR.PA', 'ENGI.PA', 'FP.PA', 'DG.PA', 'VIV.PA',\n",
    "              'UG.PA', 'SU.PA', 'VIE.PA', 'ALPHA.PA', 'ALBIO.PA', 'CRI.PA', 'ALERS.PA']\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "\n",
    "for symbol in symbol_list:\n",
    "    print('Processing {}...'.format(symbol))\n",
    "    symbol_X_df = utils.get_stock_feature_dataset(symbol)\n",
    "    symbol_X_df, symbol_y_df = make_labels_dataset(symbol_X_df)\n",
    "\n",
    "    # reset index since dates are not required for classification\n",
    "    X_df = X_df.append(symbol_X_df.reset_index(drop=True), ignore_index=True)\n",
    "    y_df = y_df.append(symbol_y_df.reset_index(drop=True), ignore_index=True)\n",
    "    print('Done! new X_df shape: {}, new y_df shape: {}'.format(X_df.shape, y_df.shape))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df.astype(float)\n",
    "X_df.replace(np.inf, np.nan, inplace=True)\n",
    "X_df.replace(-np.inf, np.nan, inplace=True)\n",
    "X_df.interpolate(axis=0, limit_direction='both', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>cac40_Open</th>\n",
       "      <th>cac40_High</th>\n",
       "      <th>cac40_Low</th>\n",
       "      <th>cac40_Close</th>\n",
       "      <th>sbf120_Open</th>\n",
       "      <th>sbf120_High</th>\n",
       "      <th>sbf120_Low</th>\n",
       "      <th>sbf120_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.854301</td>\n",
       "      <td>36.306599</td>\n",
       "      <td>34.771301</td>\n",
       "      <td>35.061798</td>\n",
       "      <td>10.226519</td>\n",
       "      <td>904282.0</td>\n",
       "      <td>-5.620798e+05</td>\n",
       "      <td>904282.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.539366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6024.379883</td>\n",
       "      <td>6102.120117</td>\n",
       "      <td>5901.770020</td>\n",
       "      <td>5917.370117</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.061798</td>\n",
       "      <td>34.999500</td>\n",
       "      <td>32.613701</td>\n",
       "      <td>33.505798</td>\n",
       "      <td>9.772677</td>\n",
       "      <td>1381445.0</td>\n",
       "      <td>-9.104260e+05</td>\n",
       "      <td>-477163.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.539366</td>\n",
       "      <td>-4.437879</td>\n",
       "      <td>5922.229980</td>\n",
       "      <td>5925.069824</td>\n",
       "      <td>5657.200195</td>\n",
       "      <td>5672.020020</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.779701</td>\n",
       "      <td>33.402100</td>\n",
       "      <td>32.281700</td>\n",
       "      <td>33.194599</td>\n",
       "      <td>9.681908</td>\n",
       "      <td>853763.0</td>\n",
       "      <td>-3.729013e+05</td>\n",
       "      <td>-1330926.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.933132</td>\n",
       "      <td>-5.325451</td>\n",
       "      <td>5521.830078</td>\n",
       "      <td>5589.500000</td>\n",
       "      <td>5461.589844</td>\n",
       "      <td>5479.700195</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.758900</td>\n",
       "      <td>36.223598</td>\n",
       "      <td>32.696701</td>\n",
       "      <td>35.580399</td>\n",
       "      <td>10.377778</td>\n",
       "      <td>1387137.0</td>\n",
       "      <td>5.082923e+05</td>\n",
       "      <td>56211.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>6.940771</td>\n",
       "      <td>1.479106</td>\n",
       "      <td>5485.930176</td>\n",
       "      <td>5530.259766</td>\n",
       "      <td>5388.850098</td>\n",
       "      <td>5450.109863</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.580399</td>\n",
       "      <td>37.136398</td>\n",
       "      <td>34.958000</td>\n",
       "      <td>35.144798</td>\n",
       "      <td>10.250728</td>\n",
       "      <td>2198233.0</td>\n",
       "      <td>-1.312943e+06</td>\n",
       "      <td>-2142022.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.231828</td>\n",
       "      <td>0.236725</td>\n",
       "      <td>5423.879883</td>\n",
       "      <td>5561.689941</td>\n",
       "      <td>5423.879883</td>\n",
       "      <td>5539.609863</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close  Adj Close     Volume  \\\n",
       "0  34.854301  36.306599  34.771301  35.061798  10.226519   904282.0   \n",
       "1  35.061798  34.999500  32.613701  33.505798   9.772677  1381445.0   \n",
       "2  32.779701  33.402100  32.281700  33.194599   9.681908   853763.0   \n",
       "3  32.758900  36.223598  32.696701  35.580399  10.377778  1387137.0   \n",
       "4  35.580399  37.136398  34.958000  35.144798  10.250728  2198233.0   \n",
       "\n",
       "     volume_adi  volume_obv  volume_cmf      volume_fi  ...  others_dlr  \\\n",
       "0 -5.620798e+05    904282.0   -0.402545 -833509.084988  ...   -4.539366   \n",
       "1 -9.104260e+05   -477163.0   -0.402545 -833509.084988  ...   -4.539366   \n",
       "2 -3.729013e+05  -1330926.0   -0.402545 -833509.084988  ...   -0.933132   \n",
       "3  5.082923e+05     56211.0   -0.402545 -833509.084988  ...    6.940771   \n",
       "4 -1.312943e+06  -2142022.0   -0.402545 -833509.084988  ...   -1.231828   \n",
       "\n",
       "   others_cr   cac40_Open   cac40_High    cac40_Low  cac40_Close  sbf120_Open  \\\n",
       "0   0.000000  6024.379883  6102.120117  5901.770020  5917.370117  4035.110107   \n",
       "1  -4.437879  5922.229980  5925.069824  5657.200195  5672.020020  3873.149902   \n",
       "2  -5.325451  5521.830078  5589.500000  5461.589844  5479.700195  3743.870117   \n",
       "3   1.479106  5485.930176  5530.259766  5388.850098  5450.109863  3728.080078   \n",
       "4   0.236725  5423.879883  5561.689941  5423.879883  5539.609863  3794.070068   \n",
       "\n",
       "   sbf120_High   sbf120_Low  sbf120_Close  \n",
       "0  4035.110107  4035.110107   4035.110107  \n",
       "1  3873.149902  3873.149902   3873.149902  \n",
       "2  3743.870117  3743.870117   3743.870117  \n",
       "3  3728.080078  3728.080078   3728.080078  \n",
       "4  3794.070068  3794.070068   3794.070068  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>increase_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  increase_tomorrow\n",
       "0                 0\n",
       "1                 0\n",
       "2                 1\n",
       "3                 0\n",
       "4                 0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = utils.split_dataset(X_df, y_df, train_size=0.9, do_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains 4.01% records labeled as 1\n",
      "testing set contains 3.73% records labeled as 1\n"
     ]
    }
   ],
   "source": [
    "# Check if there are both labels in the training and testing sets\n",
    "print('training set contains {:.2f}% records labeled as 1'.format((train_y.values.sum()/train_y.shape[0] * 100)))\n",
    "print('testing set contains {:.2f}% records labeled as 1'.format(test_y.values.sum()/test_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(train_X.values)\n",
    "\n",
    "train_X_scaled = X_scaler.transform(train_X.values)\n",
    "test_X_scaled = X_scaler.transform(test_X.values)\n",
    "\n",
    "train_y = train_y.values.reshape(-1)\n",
    "test_y = test_y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 92.55%\n",
      "\tprecision: 2.87%\n",
      "\tfbeta: 0.029\n",
      "Wall time: 15.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(DummyClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 83.49%\n",
      "\tprecision: 15.48%\n",
      "\tfbeta: 0.184\n",
      "Wall time: 6min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LinearSVC(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 82.76%\n",
      "\tprecision: 14.90%\n",
      "\tfbeta: 0.178\n",
      "Wall time: 5.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LogisticRegression(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 88.82%\n",
      "\tprecision: 21.36%\n",
      "\tfbeta: 0.249\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SVC(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 84.73%\n",
      "\tprecision: 16.51%\n",
      "\tfbeta: 0.196\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SGDClassifier(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 97.78%\n",
      "\tprecision: 95.24%\n",
      "\tfbeta: 0.763\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(KNeighborsClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 97.88%\n",
      "\tprecision: 99.31%\n",
      "\tfbeta: 0.790\n",
      "Wall time: 24min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(RandomForestClassifier(n_estimators=2000, class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 96.91%\n",
      "\tprecision: 60.07%\n",
      "\tfbeta: 0.579\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weak_learner = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "ada_model = AdaBoostClassifier(weak_learner, algorithm=\"SAMME\", n_estimators=2000)\n",
    "train_eval(ada_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier, RandomForestClassifier and AdaBoostClassifier got very good results, let's try to tune their hyperparameters with a grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(fbeta_score, beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_clf = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 5, 10],\n",
    "    'leaf_size': [10, 30, 50],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2, 3]\n",
    "}\n",
    "grid_obj = GridSearchCV(estimator=kn_clf, param_grid=parameters, scoring=scorer)\n",
    "grid_fit = grid_obj.fit(train_X_scaled, train_y)\n",
    "best_kn_clf = grid_fit.best_estimator_\n",
    "preds = best_kn_clf.predict(test_X_scaled)\n",
    "print_metrics(test_y, preds)\n",
    "\n",
    "# Save model to disk\n",
    "outfile = open('best-kneighbors-clf.pickle', 'wb')\n",
    "pickle.dump(best_kn_clf, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance used by KNeighborsClassifier\n",
    "utils.plot_feature_importance(best_kn_clf.feature_importances_, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "parameters = {\n",
    "    'n_estimators': [100, 500, 2000],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "grid_obj = GridSearchCV(estimator=rf_clf, param_grid=parameters, scoring=scorer)\n",
    "grid_fit = grid_obj.fit(train_X_scaled, train_y)\n",
    "best_rf_clf = grid_fit.best_estimator_\n",
    "preds = best_rf_clf.predict(test_X_scaled)\n",
    "print_metrics(test_y, preds)\n",
    "\n",
    "# Save model to disk\n",
    "outfile = open('best-randomforest-clf.pickle', 'wb')\n",
    "pickle.dump(best_rf_clf, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance used by RandomForestClassifier\n",
    "utils.plot_feature_importance(best_rf_clf.feature_importances_, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_learner = DecisionTreeClassifier(class_weight='balanced')\n",
    "ada_clf = AdaBoostClassifier(weak_learner)\n",
    "parameters = {\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'learning_rate': [0.5, 1.0, 2],\n",
    "    'n_estimators': [100, 500, 2000],\n",
    "    'base_estimator__criterion': ['gini', 'entropy'],\n",
    "    'base_estimator__splitter': ['best', 'random'],\n",
    "    'base_estimator__max_depth': [10, 20, 30]\n",
    "}\n",
    "grid_obj = GridSearchCV(estimator=ada_clf, param_grid=parameters, scoring=scorer)\n",
    "grid_fit = grid_obj.fit(train_X_scaled, train_y)\n",
    "best_ada_clf = grid_fit.best_estimator_\n",
    "preds = best_ada_clf.predict(test_X_scaled)\n",
    "print_metrics(test_y, preds)\n",
    "\n",
    "# Save model to disk\n",
    "outfile = open('best-adaboost-clf.pickle', 'wb')\n",
    "pickle.dump(best_ada_clf, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance used by AdaBoostClassifier\n",
    "utils.plot_feature_importance(best_ada_clf.feature_importances_, train_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
