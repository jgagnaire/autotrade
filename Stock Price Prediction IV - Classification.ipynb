{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have previously appplied several regression models and analyzed their results. They were not reliable enough to be used for real-world portfolio management.\n",
    "\n",
    "Another way to approach the main problem of stock market investing is to consider it as a classification problem: can a model predict well enough if a stock price will increase by 5% or more in the next day ?\n",
    "\n",
    "Let's investigate by building the appropriate dataset, and train various classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.23.1)\n",
      "Requirement already satisfied: ta in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.5.25)\n",
      "Requirement already satisfied: requests in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (0.10.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda3\\lib\\site-packages (from requests->-r requirements.txt (line 5)) (2020.4.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 1)) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, fbeta_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "X_df = utils.get_stock_feature_dataset('ALNOV.PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>cac40_Open</th>\n",
       "      <th>cac40_High</th>\n",
       "      <th>cac40_Low</th>\n",
       "      <th>cac40_Close</th>\n",
       "      <th>sbf120_Open</th>\n",
       "      <th>sbf120_High</th>\n",
       "      <th>sbf120_Low</th>\n",
       "      <th>sbf120_Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-12</th>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.561258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3401.260010</td>\n",
       "      <td>3419.000000</td>\n",
       "      <td>3389.080078</td>\n",
       "      <td>3389.080078</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "      <td>2607.149902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-15</th>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.48</td>\n",
       "      <td>730.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.561258</td>\n",
       "      <td>-2.528736</td>\n",
       "      <td>3387.760010</td>\n",
       "      <td>3439.520020</td>\n",
       "      <td>3387.760010</td>\n",
       "      <td>3420.280029</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "      <td>2630.100098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-16</th>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.70</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>2.561258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3443.600098</td>\n",
       "      <td>3500.939941</td>\n",
       "      <td>3428.969971</td>\n",
       "      <td>3500.939941</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "      <td>2686.030029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-17</th>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.72</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3520.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229621</td>\n",
       "      <td>0.229885</td>\n",
       "      <td>3503.820068</td>\n",
       "      <td>3530.790039</td>\n",
       "      <td>3494.350098</td>\n",
       "      <td>3527.500000</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "      <td>2704.060059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-18</th>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>8.83</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-24.874197</td>\n",
       "      <td>...</td>\n",
       "      <td>1.253578</td>\n",
       "      <td>1.494253</td>\n",
       "      <td>3527.760010</td>\n",
       "      <td>3542.580078</td>\n",
       "      <td>3508.399902</td>\n",
       "      <td>3535.179932</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "      <td>2709.370117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close  Volume  volume_adi  \\\n",
       "Date                                                                 \n",
       "2012-10-12  8.70  8.70  8.70   8.70       8.70   450.0         0.0   \n",
       "2012-10-15  8.48  8.48  8.48   8.48       8.48   730.0         0.0   \n",
       "2012-10-16  8.70  8.70  8.70   8.70       8.70  3000.0         0.0   \n",
       "2012-10-17  8.72  8.72  8.72   8.72       8.72   800.0         0.0   \n",
       "2012-10-18  8.83  8.83  8.83   8.83       8.83   138.0         0.0   \n",
       "\n",
       "            volume_obv  volume_cmf  volume_fi  ...  others_dlr  others_cr  \\\n",
       "Date                                           ...                          \n",
       "2012-10-12       450.0         0.0 -24.874197  ...   -2.561258   0.000000   \n",
       "2012-10-15      -280.0         0.0 -24.874197  ...   -2.561258  -2.528736   \n",
       "2012-10-16      2720.0         0.0 -24.874197  ...    2.561258   0.000000   \n",
       "2012-10-17      3520.0         0.0 -24.874197  ...    0.229621   0.229885   \n",
       "2012-10-18      3658.0         0.0 -24.874197  ...    1.253578   1.494253   \n",
       "\n",
       "             cac40_Open   cac40_High    cac40_Low  cac40_Close  sbf120_Open  \\\n",
       "Date                                                                          \n",
       "2012-10-12  3401.260010  3419.000000  3389.080078  3389.080078  2607.149902   \n",
       "2012-10-15  3387.760010  3439.520020  3387.760010  3420.280029  2630.100098   \n",
       "2012-10-16  3443.600098  3500.939941  3428.969971  3500.939941  2686.030029   \n",
       "2012-10-17  3503.820068  3530.790039  3494.350098  3527.500000  2704.060059   \n",
       "2012-10-18  3527.760010  3542.580078  3508.399902  3535.179932  2709.370117   \n",
       "\n",
       "            sbf120_High   sbf120_Low  sbf120_Close  \n",
       "Date                                                \n",
       "2012-10-12  2607.149902  2607.149902   2607.149902  \n",
       "2012-10-15  2630.100098  2630.100098   2630.100098  \n",
       "2012-10-16  2686.030029  2686.030029   2686.030029  \n",
       "2012-10-17  2704.060059  2704.060059   2704.060059  \n",
       "2012-10-18  2709.370117  2709.370117   2709.370117  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels_dataset(X_df, increase=0.05, label_name='increase_tomorrow'):\n",
    "    '''\n",
    "        increase: float between 0 and 1, equivalent to the desired % increase when multiplied by 100\n",
    "        label_name: name for the column containing labels\n",
    "    '''\n",
    "\n",
    "    # Build the target dataset: label 1 if stock price increased by 5% or more in the following days, 0 otherwise\n",
    "    y_df = pd.DataFrame(index=X_df.index, columns=[label_name])\n",
    "    for i in range(len(X_df) - 1):\n",
    "        increase_threshold = X_df['Adj Close'].iloc[i] + increase * X_df['Adj Close'].iloc[i]\n",
    "        y_df.iloc[i] = 1 if X_df['Adj Close'].iloc[i+1] > increase_threshold else 0\n",
    "\n",
    "    # Drop last row, for which there is no label\n",
    "    X_df.drop(X_df.tail(1).index, inplace=True)\n",
    "    y_df.drop(y_df.tail(1).index, inplace=True)\n",
    "\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = make_labels_dataset(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>increase_tomorrow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           increase_tomorrow\n",
       "Date                        \n",
       "2020-06-30                 0\n",
       "2020-07-01                 0\n",
       "2020-07-02                 1\n",
       "2020-07-03                 0\n",
       "2020-07-06                 0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's check if this 31.62% increase is correctly labeled...\n",
      "Good!\n"
     ]
    }
   ],
   "source": [
    "# Check that labels are correct:\n",
    "\n",
    "# There was an important increase of our stock price on the market day just after April 9th 2020\n",
    "print(\"Let's check if this {:.2f}% increase is correctly labeled...\".format((X_df.loc['2020-04-14']['Adj Close'] - X_df.loc['2020-04-09']['Adj Close']) / X_df.loc['2020-04-09']['Adj Close'] * 100))\n",
    "\n",
    "# Get index of April 9th 2020, the day before increase\n",
    "idx = len(X_df.loc[:'2020-04-09']) - 1\n",
    "assert np.array_equal(X_df.loc['2020-04-09'].values, X_df.iloc[idx].values)\n",
    "\n",
    "# Check that its corresponding label is 1\n",
    "assert y_df.iloc[idx]['increase_tomorrow'] == 1\n",
    "\n",
    "print('Good!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split dataset into testing and training datasets, and normalize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 90-10% training-testing sets.\n",
    "# They can be shuffled safely, since the specificities of\n",
    "# time series are not relevant anymore for our classification task\n",
    "train_X, train_y, test_X, test_y = utils.split_dataset(X_df, y_df, train_size=0.9, do_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains 7.27% records labeled as 1\n",
      "testing set contains 9.14% records labeled as 1\n"
     ]
    }
   ],
   "source": [
    "# Check if there are both labels in the training and testing sets\n",
    "print('training set contains {:.2f}% records labeled as 1'.format((train_y.values.sum()/train_y.shape[0] * 100)))\n",
    "print('testing set contains {:.2f}% records labeled as 1'.format(test_y.values.sum()/test_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(train_X.values)\n",
    "\n",
    "train_X_scaled = X_scaler.transform(train_X.values)\n",
    "test_X_scaled = X_scaler.transform(test_X.values)\n",
    "\n",
    "train_y = train_y.values.reshape(-1)\n",
    "test_y = test_y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first use the benchmark algorithm 'DummyClassifier', and then apply and test LinearSVC, LogisticRegression, SVC, KNeighborsClassifier, RandomForestClassifier and AdaBoostClassifier.\n",
    "\n",
    "The metrics I will evaluate for this classification task are accuracy, precision and Fbeta-score with beta=0.5 to penalize false positives more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    print('\\taccuracy: {:.2f}%'.format(accuracy_score(y_true, y_pred) * 100))\n",
    "    print('\\tprecision: {:.2f}%'.format(precision_score(y_true, y_pred) * 100))\n",
    "    print('\\tfbeta: {:.3f}'.format(fbeta_score(y_true, y_pred, beta=0.5)))\n",
    "\n",
    "def train_eval(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(test_X)\n",
    "    print('Results:')\n",
    "    print_metrics(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 85.79%\n",
      "\tprecision: 18.75%\n",
      "\tfbeta: 0.183\n",
      "Wall time: 15.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(DummyClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 78.17%\n",
      "\tprecision: 26.42%\n",
      "\tfbeta: 0.304\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LinearSVC(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 67.01%\n",
      "\tprecision: 18.67%\n",
      "\tfbeta: 0.220\n",
      "Wall time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SGDClassifier(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 76.14%\n",
      "\tprecision: 24.56%\n",
      "\tfbeta: 0.285\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LogisticRegression(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 80.71%\n",
      "\tprecision: 27.27%\n",
      "\tfbeta: 0.309\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SVC(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 90.36%\n",
      "\tprecision: 42.86%\n",
      "\tfbeta: 0.326\n",
      "Wall time: 62.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(KNeighborsClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 90.36%\n",
      "\tprecision: 33.33%\n",
      "\tfbeta: 0.167\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(RandomForestClassifier(n_estimators=2000, class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 88.83%\n",
      "\tprecision: 16.67%\n",
      "\tfbeta: 0.119\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weak_learner = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "ada_model = AdaBoostClassifier(weak_learner, algorithm=\"SAMME\", n_estimators=2000)\n",
    "train_eval(ada_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and fbeta scores obtained by all these classifiers are not very good, the current dataset is most probably not adapted to this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then try to get less overfitting and better precision and fbeta scores by aggregating a lot more stocks than just one in our training and testing sets, and re-train all these models on much more data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AI.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! new X_df shape: (5273, 86), new y_df shape: (5273, 1)\n",
      "\n",
      "Processing SAF.PA...\n",
      "Done! new X_df shape: (10546, 86), new y_df shape: (10546, 1)\n",
      "\n",
      "Processing GNFT.PA...\n",
      "Done! new X_df shape: (12602, 86), new y_df shape: (12602, 1)\n",
      "\n",
      "Processing ALNOV.PA...\n",
      "Done! new X_df shape: (14574, 86), new y_df shape: (14574, 1)\n",
      "\n",
      "Processing FDJ.PA...\n",
      "Done! new X_df shape: (14732, 86), new y_df shape: (14732, 1)\n",
      "\n",
      "Processing ETL.PA...\n",
      "Done! new X_df shape: (18461, 86), new y_df shape: (18461, 1)\n",
      "\n",
      "Processing DBV.PA...\n",
      "Done! new X_df shape: (20517, 86), new y_df shape: (20517, 1)\n",
      "\n",
      "Processing BN.PA...\n",
      "Done! new X_df shape: (28289, 86), new y_df shape: (28289, 1)\n",
      "\n",
      "Processing KER.PA...\n",
      "Done! new X_df shape: (33562, 86), new y_df shape: (33562, 1)\n",
      "\n",
      "Processing AIR.PA...\n",
      "Done! new X_df shape: (38400, 86), new y_df shape: (38400, 1)\n",
      "\n",
      "Processing ENGI.PA...\n",
      "Done! new X_df shape: (43673, 86), new y_df shape: (43673, 1)\n",
      "\n",
      "Processing FP.PA...\n",
      "Done! new X_df shape: (48946, 86), new y_df shape: (48946, 1)\n",
      "\n",
      "Processing DG.PA...\n",
      "Done! new X_df shape: (54219, 86), new y_df shape: (54219, 1)\n",
      "\n",
      "Processing VIV.PA...\n",
      "Done! new X_df shape: (59492, 86), new y_df shape: (59492, 1)\n",
      "\n",
      "Processing UG.PA...\n",
      "Done! new X_df shape: (64765, 86), new y_df shape: (64765, 1)\n",
      "\n",
      "Processing SU.PA...\n",
      "Done! new X_df shape: (70038, 86), new y_df shape: (70038, 1)\n",
      "\n",
      "Processing VIE.PA...\n",
      "Done! new X_df shape: (75168, 86), new y_df shape: (75168, 1)\n",
      "\n",
      "Processing ALPHA.PA...\n",
      "Done! new X_df shape: (76183, 86), new y_df shape: (76183, 1)\n",
      "\n",
      "Processing ALBIO.PA...\n",
      "Done! new X_df shape: (78553, 86), new y_df shape: (78553, 1)\n",
      "\n",
      "Processing CRI.PA...\n",
      "Done! new X_df shape: (84746, 86), new y_df shape: (84746, 1)\n",
      "\n",
      "Processing ALERS.PA...\n",
      "Done! new X_df shape: (86802, 86), new y_df shape: (86802, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "symbol_list = ['AI.PA', 'SAF.PA', 'GNFT.PA', 'ALNOV.PA', 'FDJ.PA', 'ETL.PA', 'DBV.PA',\n",
    "              'BN.PA', 'KER.PA', 'AIR.PA', 'ENGI.PA', 'FP.PA', 'DG.PA', 'VIV.PA',\n",
    "              'UG.PA', 'SU.PA', 'VIE.PA', 'ALPHA.PA', 'ALBIO.PA', 'CRI.PA', 'ALERS.PA']\n",
    "\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "\n",
    "for symbol in symbol_list:\n",
    "    print('Processing {}...'.format(symbol))\n",
    "    symbol_X_df = utils.get_stock_feature_dataset(symbol)\n",
    "    symbol_X_df, symbol_y_df = make_labels_dataset(symbol_X_df)\n",
    "\n",
    "    # reset index since dates are not required for classification\n",
    "    X_df = X_df.append(symbol_X_df.reset_index(drop=True), ignore_index=True)\n",
    "    y_df = y_df.append(symbol_y_df.reset_index(drop=True), ignore_index=True)\n",
    "    print('Done! new X_df shape: {}, new y_df shape: {}'.format(X_df.shape, y_df.shape))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = X_df.astype(float)\n",
    "X_df.replace(np.inf, np.nan, inplace=True)\n",
    "X_df.replace(-np.inf, np.nan, inplace=True)\n",
    "X_df.interpolate(axis=0, limit_direction='both', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>cac40_Open</th>\n",
       "      <th>cac40_High</th>\n",
       "      <th>cac40_Low</th>\n",
       "      <th>cac40_Close</th>\n",
       "      <th>sbf120_Open</th>\n",
       "      <th>sbf120_High</th>\n",
       "      <th>sbf120_Low</th>\n",
       "      <th>sbf120_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.854301</td>\n",
       "      <td>36.306599</td>\n",
       "      <td>34.771301</td>\n",
       "      <td>35.061798</td>\n",
       "      <td>10.226519</td>\n",
       "      <td>904282.0</td>\n",
       "      <td>-5.620798e+05</td>\n",
       "      <td>904282.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.539366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6024.379883</td>\n",
       "      <td>6102.120117</td>\n",
       "      <td>5901.770020</td>\n",
       "      <td>5917.370117</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "      <td>4035.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.061798</td>\n",
       "      <td>34.999500</td>\n",
       "      <td>32.613701</td>\n",
       "      <td>33.505798</td>\n",
       "      <td>9.772677</td>\n",
       "      <td>1381445.0</td>\n",
       "      <td>-9.104260e+05</td>\n",
       "      <td>-477163.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.539366</td>\n",
       "      <td>-4.437879</td>\n",
       "      <td>5922.229980</td>\n",
       "      <td>5925.069824</td>\n",
       "      <td>5657.200195</td>\n",
       "      <td>5672.020020</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "      <td>3873.149902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.779701</td>\n",
       "      <td>33.402100</td>\n",
       "      <td>32.281700</td>\n",
       "      <td>33.194599</td>\n",
       "      <td>9.681908</td>\n",
       "      <td>853763.0</td>\n",
       "      <td>-3.729013e+05</td>\n",
       "      <td>-1330926.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.933132</td>\n",
       "      <td>-5.325451</td>\n",
       "      <td>5521.830078</td>\n",
       "      <td>5589.500000</td>\n",
       "      <td>5461.589844</td>\n",
       "      <td>5479.700195</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "      <td>3743.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.758900</td>\n",
       "      <td>36.223598</td>\n",
       "      <td>32.696701</td>\n",
       "      <td>35.580399</td>\n",
       "      <td>10.377778</td>\n",
       "      <td>1387137.0</td>\n",
       "      <td>5.082923e+05</td>\n",
       "      <td>56211.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>6.940771</td>\n",
       "      <td>1.479106</td>\n",
       "      <td>5485.930176</td>\n",
       "      <td>5530.259766</td>\n",
       "      <td>5388.850098</td>\n",
       "      <td>5450.109863</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "      <td>3728.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.580399</td>\n",
       "      <td>37.136398</td>\n",
       "      <td>34.958000</td>\n",
       "      <td>35.144798</td>\n",
       "      <td>10.250728</td>\n",
       "      <td>2198233.0</td>\n",
       "      <td>-1.312943e+06</td>\n",
       "      <td>-2142022.0</td>\n",
       "      <td>-0.402545</td>\n",
       "      <td>-833509.084988</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.231828</td>\n",
       "      <td>0.236725</td>\n",
       "      <td>5423.879883</td>\n",
       "      <td>5561.689941</td>\n",
       "      <td>5423.879883</td>\n",
       "      <td>5539.609863</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "      <td>3794.070068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close  Adj Close     Volume  \\\n",
       "0  34.854301  36.306599  34.771301  35.061798  10.226519   904282.0   \n",
       "1  35.061798  34.999500  32.613701  33.505798   9.772677  1381445.0   \n",
       "2  32.779701  33.402100  32.281700  33.194599   9.681908   853763.0   \n",
       "3  32.758900  36.223598  32.696701  35.580399  10.377778  1387137.0   \n",
       "4  35.580399  37.136398  34.958000  35.144798  10.250728  2198233.0   \n",
       "\n",
       "     volume_adi  volume_obv  volume_cmf      volume_fi  ...  others_dlr  \\\n",
       "0 -5.620798e+05    904282.0   -0.402545 -833509.084988  ...   -4.539366   \n",
       "1 -9.104260e+05   -477163.0   -0.402545 -833509.084988  ...   -4.539366   \n",
       "2 -3.729013e+05  -1330926.0   -0.402545 -833509.084988  ...   -0.933132   \n",
       "3  5.082923e+05     56211.0   -0.402545 -833509.084988  ...    6.940771   \n",
       "4 -1.312943e+06  -2142022.0   -0.402545 -833509.084988  ...   -1.231828   \n",
       "\n",
       "   others_cr   cac40_Open   cac40_High    cac40_Low  cac40_Close  sbf120_Open  \\\n",
       "0   0.000000  6024.379883  6102.120117  5901.770020  5917.370117  4035.110107   \n",
       "1  -4.437879  5922.229980  5925.069824  5657.200195  5672.020020  3873.149902   \n",
       "2  -5.325451  5521.830078  5589.500000  5461.589844  5479.700195  3743.870117   \n",
       "3   1.479106  5485.930176  5530.259766  5388.850098  5450.109863  3728.080078   \n",
       "4   0.236725  5423.879883  5561.689941  5423.879883  5539.609863  3794.070068   \n",
       "\n",
       "   sbf120_High   sbf120_Low  sbf120_Close  \n",
       "0  4035.110107  4035.110107   4035.110107  \n",
       "1  3873.149902  3873.149902   3873.149902  \n",
       "2  3743.870117  3743.870117   3743.870117  \n",
       "3  3728.080078  3728.080078   3728.080078  \n",
       "4  3794.070068  3794.070068   3794.070068  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>increase_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  increase_tomorrow\n",
       "0                 0\n",
       "1                 0\n",
       "2                 1\n",
       "3                 0\n",
       "4                 0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = utils.split_dataset(X_df, y_df, train_size=0.9, do_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set contains 3.98% records labeled as 1\n",
      "testing set contains 4.08% records labeled as 1\n"
     ]
    }
   ],
   "source": [
    "# Check if there are both labels in the training and testing sets\n",
    "print('training set contains {:.2f}% records labeled as 1'.format((train_y.values.sum()/train_y.shape[0] * 100)))\n",
    "print('testing set contains {:.2f}% records labeled as 1'.format(test_y.values.sum()/test_y.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all values to have the same range:\n",
    "X_scaler = MinMaxScaler().fit(train_X.values)\n",
    "\n",
    "train_X_scaled = X_scaler.transform(train_X.values)\n",
    "test_X_scaled = X_scaler.transform(test_X.values)\n",
    "\n",
    "train_y = train_y.values.reshape(-1)\n",
    "test_y = test_y.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 92.38%\n",
      "\tprecision: 3.63%\n",
      "\tfbeta: 0.036\n",
      "Wall time: 15.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(DummyClassifier(), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 84.77%\n",
      "\tprecision: 18.45%\n",
      "\tfbeta: 0.218\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LinearSVC(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 84.17%\n",
      "\tprecision: 17.72%\n",
      "\tfbeta: 0.210\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(LogisticRegression(class_weight='balanced', max_iter=100000), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 89.64%\n",
      "\tprecision: 24.84%\n",
      "\tfbeta: 0.287\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SVC(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 94.84%\n",
      "\tprecision: 41.03%\n",
      "\tfbeta: 0.439\n",
      "Wall time: 793 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_eval(SGDClassifier(class_weight='balanced'), train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 97.64%\n",
      "\tprecision: 94.61%\n",
      "\tfbeta: 0.773\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kn_model = KNeighborsClassifier()\n",
    "train_eval(kn_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 97.75%\n",
      "\tprecision: 99.38%\n",
      "\tfbeta: 0.802\n",
      "Wall time: 22min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestClassifier(n_estimators=2000, class_weight='balanced')\n",
    "train_eval(rf_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\taccuracy: 92.30%\n",
      "\tprecision: 29.40%\n",
      "\tfbeta: 0.329\n",
      "Wall time: 51.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "weak_learner = DecisionTreeClassifier(max_depth=10, class_weight='balanced')\n",
    "ada_model = AdaBoostClassifier(weak_learner, algorithm=\"SAMME\", n_estimators=2000)\n",
    "train_eval(ada_model, train_X_scaled, train_y, test_X_scaled, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier and RandomForestClassifier got very good results, let's write them to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save KNN model to disk\n",
    "outfile = open('kneighbors-clf.pickle', 'wb')\n",
    "pickle.dump(kn_model, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk\n",
    "outfile = open('randomforest-clf.pickle', 'wb')\n",
    "pickle.dump(rf_model, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top N most important features used by RandomForestClassifier\n",
    "importances = rf_model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "top_n = 10\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(top_n+1), importances[indices[:top_n+1]], align=\"center\")\n",
    "plt.xticks(range(top_n+1), X_df.columns[indices[:top_n+1]], rotation=90)\n",
    "plt.xlim([-1, top_n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the PCA study performed earlier, the feature importance plot shows that the RF model works by using a top-10-feature mix of both traditional technical analysis indicators and features related to the main market indices of the stocks analyzed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
